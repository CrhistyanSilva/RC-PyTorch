{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRAN: using Agg backend linux\n",
      "***No CUDA syncs for timings\n",
      "Getting lock for /scratch_net/fryr/mentzerf/datasets/DIV2K_new/DIV2K_valid_HR_crop4/cached_glob.pkl: .cached_glob.lock [reset: False]...\n",
      ">>> filter [min_size=52; discard_s=False]: 0.00094\n",
      "Getting lock for /scratch_net/fryr/mentzerf/datasets/DIV2K_new/DIV2K_valid_HR_crop4_bpg_q13/cached_glob.pkl: .cached_glob.lock [reset: False]...\n",
      ">>> filter [min_size=52; discard_s=False]: 0.00068\n",
      "Sorting...\n",
      "Got 1 datasets.\n",
      "Testing 1108_2150 at -1 ---\n",
      "*** global_config fw_s=3\n",
      "*** global_config long_means\n",
      "*** global_config long_pis\n",
      "*** global_config long_sigma\n",
      "*** global_config gdn\n",
      "*** global_config no_norm_final\n",
      "*** global_config down_up=deconv\n",
      "Updating config.lr.initial = 1e-05\n",
      "Using global_config: GlobalConfig(\n",
      "\tdown_up=deconv\n",
      "\tfw_s=3\n",
      "\tgdn\n",
      "\tlong_means\n",
      "\tlong_pis\n",
      "\tlong_sigma\n",
      "\tlr.initial=1e-05\n",
      "\tno_norm_final\n",
      "\tunet_skip)\n",
      "*** no norm for final\n",
      "*** DownUp, adding DeconvUp()\n",
      "filter_width for sigma = 3\n",
      "Did set tail_networks.sigmas\n",
      "Did set tail_networks.means\n",
      "Did set tail_networks.pis\n",
      "Setting tail_networks[ dict_keys(['sigmas', 'means', 'pis']) ]\n",
      "EB: self.cin_style = None\n",
      "******************************\n",
      "*** Padding by a factor 2\n",
      "******************************\n",
      "*** Ignoring 0 ckpts after 1573579348.4084997\n",
      "Restoring /scratch_net/fryr_third/mentzerf/logs/jointlogs/1108_2150 en@gdn_wide_deep3 new_oi_q12_14_128 lr.initial=1e-05 unet_skip/ckpts/ckpt_0000437250.pt.tmp... (strict=True)\n",
      "Convert disabled...\n",
      "EnhancementNetwork(\n",
      "  (head): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (down): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (unet_skip_conv): Sequential(\n",
      "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "  )\n",
      "  (body): Sequential(\n",
      "    (0): ResBlock(Conv(128x3)/N(128)/ReLU(inplace)/Conv(128x3)/N(128)/res_scale=0.1)\n",
      "    (1): ResBlock(Conv(128x3)/N(128)/ReLU(inplace)/Conv(128x3)/N(128)/res_scale=0.1)\n",
      "    (2): ResBlock(Conv(128x3)/N(128)/ReLU(inplace)/Conv(128x3)/N(128)/res_scale=0.1)\n",
      "    (3): ResBlock(Conv(128x3)/N(128)/ReLU(inplace)/Conv(128x3)/N(128)/res_scale=0.1)\n",
      "    (4): ResBlock(Conv(128x3)/N(128)/ReLU(inplace)/Conv(128x3)/N(128)/res_scale=0.1)\n",
      "    (5): ResBlock(Conv(128x3)/N(128)/ReLU(inplace)/Conv(128x3)/N(128)/res_scale=0.1)\n",
      "    (6): ResBlock(Conv(128x3)/N(128)/ReLU(inplace)/Conv(128x3)/N(128)/res_scale=0.1)\n",
      "    (7): ResBlock(Conv(128x3)/N(128)/ReLU(inplace)/Conv(128x3)/N(128)/res_scale=0.1)\n",
      "    (8): ResBlock(Conv(128x3)/N(128)/ReLU(inplace)/Conv(128x3)/N(128)/res_scale=0.1)\n",
      "    (9): ResBlock(Conv(128x3)/N(128)/ReLU(inplace)/Conv(128x3)/N(128)/res_scale=0.1)\n",
      "    (10): ResBlock(Conv(128x3)/N(128)/ReLU(inplace)/Conv(128x3)/N(128)/res_scale=0.1)\n",
      "    (11): ResBlock(Conv(128x3)/N(128)/ReLU(inplace)/Conv(128x3)/N(128)/res_scale=0.1)\n",
      "    (12): ResBlock(Conv(128x3)/N(128)/ReLU(inplace)/Conv(128x3)/N(128)/res_scale=0.1)\n",
      "    (13): ResBlock(Conv(128x3)/N(128)/ReLU(inplace)/Conv(128x3)/N(128)/res_scale=0.1)\n",
      "    (14): ResBlock(Conv(128x3)/N(128)/ReLU(inplace)/Conv(128x3)/N(128)/res_scale=0.1)\n",
      "    (15): ResBlock(Conv(128x3)/N(128)/ReLU(inplace)/Conv(128x3)/N(128)/res_scale=0.1)\n",
      "    (16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (after_skip): DeconvUp()\n",
      "  (tail): ProbClfTail(\n",
      "    (means): FeatureMapSaverSequential(\n",
      "      (0): ResBlock(Conv(128x3)/ReLU(inplace)/Conv(128x3)/res_scale=0.1)\n",
      "      (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): LeakyReLU(negative_slope=0.01, inplace)\n",
      "      (3): Conv2d(128, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (sigmas): FeatureMapSaverSequential(\n",
      "      (0): ResBlock(Conv(128x3)/ReLU(inplace)/Conv(128x3)/res_scale=0.1)\n",
      "      (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): LeakyReLU(negative_slope=0.01, inplace)\n",
      "      (3): Conv2d(128, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (pis): FeatureMapSaverSequential(\n",
      "      (0): ResBlock(Conv(128x3)/ReLU(inplace)/Conv(128x3)/res_scale=0.1)\n",
      "      (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): LeakyReLU(negative_slope=0.01, inplace)\n",
      "      (3): Conv2d(128, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (lambdas): Conv2d(128, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "[0, 0]\n"
     ]
    }
   ],
   "source": [
    "from helpers.notebook_dict import set_is_in_notebook\n",
    "\n",
    "set_is_in_notebook(True)\n",
    "\n",
    "import os\n",
    "os.environ['FORCE_AGG'] = '1'\n",
    "import numpy as np \n",
    "import IPython\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from run_test import get_tester_and_dataset\n",
    "\n",
    "T_Q10 = os.environ['T_OI_Q10']\n",
    "T_Q15 = os.environ['T_OI_Q15']\n",
    "\n",
    "os.environ['T_DIV_CROP_Q12'] = '/scratch_net/fryr/mentzerf/datasets/DIV2K_new/DIV2K_valid_HR_crop4;/scratch_net/fryr/mentzerf/datasets/DIV2K_new/DIV2K_valid_HR_crop4_bpg_q12'\n",
    "\n",
    "L_Q10 = '1002_1751'\n",
    "L_Q15 = '0930_1004'\n",
    "\n",
    "DS_OI = '/srv/beegfs02/scratch/cnncompression/data/datasets/openimages/test_768_clean_m500'\n",
    "DS_CB = 'checkerboard'\n",
    "args = [\n",
    "    os.environ['LOGS_THIRD'],# + '/AWS/',\n",
    "    '1108_2150',\n",
    "    os.environ['T_DIV_CROP_Q13'],\n",
    "#     '/scratch_net/fryr/mentzerf/datasets/DIV2K_new/DIV2K_valid_HR_crop4_multi_q8_9_10_11_12_13_14_15',\n",
    "#     '/scratch_net/fryr_second/mentzerf/datasets/RAISE_1k/RAISE_1k_raw_r100_crop16;/scratch_net/fryr_second/mentzerf/datasets/RAISE_1k/RAISE_1k_raw_r100_crop16_bpg_q12',\n",
    "#     '/home/mentzerf/net_scratch/datasets/openimages_rand/val_oi_500_r_multi_q9_10_11_12_13_14_15',\n",
    "  '--crop', '52'\n",
    "]\n",
    "t, ds = get_tester_and_dataset(args)\n",
    "\n",
    "from modules import conditional_instance_norm\n",
    "\n",
    "print(t.blueprint.net)\n",
    "\n",
    "all_vars = conditional_instance_norm._all_vars\n",
    "print([len(v) for v in all_vars.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def normalize_to_0_1(t, mi=None, ma=None):\n",
    "    if mi is None:\n",
    "        mi = t.min()\n",
    "    if ma is None:\n",
    "        ma = t.max()\n",
    "    return t.add(-mi).div(ma - mi + 1e-5)\n",
    "\n",
    "def show_tensor(t, normalize=False, mi=None, ma=None, blow_up=None, show_range=False):\n",
    "    if show_range:\n",
    "        r = t.min().item(), t.max().item()\n",
    "    if normalize:\n",
    "        t = normalize_to_0_1(t.detach(), mi, ma).mul(255.).round().to(torch.uint8)\n",
    "        \n",
    "    t = t.detach().numpy()\n",
    "    if len(t.shape) == 4:\n",
    "        t = t[0, ...]\n",
    "    t_shape = t.shape\n",
    "    if len(t.shape) == 2:\n",
    "        t = np.stack([t, t, t], -1)\n",
    "    if len(t_shape) == 3 and t_shape[0] == 3:\n",
    "        t = t.transpose(1, 2, 0)\n",
    "\n",
    "    # now is HWC\n",
    "    \n",
    "    \n",
    "    if blow_up:\n",
    "        t = t.repeat(blow_up, axis=0).repeat(blow_up, axis=1)\n",
    "    \n",
    "    if show_range:\n",
    "        print(r)\n",
    "        \n",
    "    IPython.display.display(Image.fromarray(t))\n",
    "    \n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "*****\n",
      "*****\n",
      "*****\n",
      "*****\n",
      "*****\n",
      "*****\n",
      "*****\n",
      "*****\n",
      "*****\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show_tensor(t.blueprint.net.learned_skip.weight.squeeze(), normalize=True,blow_up=5)\n",
    "\n",
    "# print(t.blueprint.net.learned_skip.weight.min())\n",
    "\n",
    "# show_tensor(t.blueprint.net.learned_skip.bias.unsqueeze(-1), normalize=True, blow_up=5)\n",
    "\n",
    "for g in all_vars['gamma']:\n",
    "    show_tensor(g, normalize=True, blow_up=10, show_range=True)\n",
    "print('*****\\n'*10)\n",
    "for g in all_vars['beta']:\n",
    "    show_tensor(g, normalize=True, blow_up=10, show_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dataloaders.compressed_images_loader.ResidualDataset'>\n",
      "dict_keys(['bpp', 'raw', 'compressed'])\n",
      "3.72271\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=52x52 at 0x7F2CBE383EB8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res\n",
      "(-5.0, 5.0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=52x52 at 0x7F2CE036EBA8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res\n",
      "(-4.0, 3.0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=52x52 at 0x7F2CBE3327B8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res\n",
      "(-4.0, 4.0)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADQAAAA0CAIAAABKGoy8AAAE+ElEQVR4nM2Z3ZXiOhCENRzykDKRMpEdidaRgDKRMpEy2YdvqOvrwcYY2DP9wGBbP9XV1a3G83W5XIwxxpjWGl+cc2afacrceu/W2j3T2ejnIgLwdblcNh6vIfgH5pw73937IaA1dt/oSWvt/DCIx9C/xe4zZ56RzgFzzu1x77T24HPIzG7iz+/a7xM5dF4s/dS6+4vOMVsmxG8oIrJv5u5W4E8T83CjZbbOL+/G+mFZN/vo/znmJ8SthHiqwrXW7uJec0bjN+wrpbQ94ilbg3LMVuvcMTsGa1Vz/Akh8KWUcmD1uR3AtzblG9zrmD5hbw7re+38q6ruwt52tu4x59xdLlY1d7csze11OheAfpbctegtmftEZDeKOY3dWnu32gnfPcdeQbMxcu0wfBzWz9lGn8adrbA+1J8Oq42+6+7e2/c1/emDf3vkgoxjcZC3by4lGw3Ys+s4537vCdFa2wXO3WxjwItQtEIIoffOdrvAtZttDDgGaBgGIQsh8CXGyHb/NKxz+qHner0aY2qtzrlpmnhUSum9mxe7km06BULGeOccrxNKKcMwgMMYE2M0xgCxlPKGhFioTU0raIwx3vuUkrXWe4+eWmsxRp7CnPdetOEtIX5DKWEbfosQEWut3mbUWuVDztlaG0IQPSmlEELOeeFbCKG19uoPHFZRcAFK7MDRWss5e+95Oj9OiGMpBZ5KKXhijLHW1lqPhxUc9Pe1Vi5RkvceuNM01VrxX5rz3gML6NxXfFmk9+693wVObOO0cHATMpRi0hP5aIzJObOZc444Ah3HmM7IWiuPrLV7E4JVVI2IV86ZXIMbVL/ID1iESEWf8FlrkRpszU9nfHPOfemFtWi4y5yUTmNYa/Xe82luhWpx/C9yAhy995TSOI5UWibqqdTJzSW4DaBaZZqmlFJrTQFSNwujbfZqgi94gpjmOYEDc53gsHMu53xegFBJlCrNrZmepsk5x0ymUBrwXq9pVUdyzjFGsSttsAj3SQhtp3L43ZWo8VIsFA6Wzjk752qtcCzmh2FgbkopxrhgpfceYwSHViNJNUaJIrECNOcM9JOIYSeJoPcODiTivS+laIMQAslPnqoiuNsPFuSFY5IdW1JZIInVZNfrlXXw4aReQDkyDIP4q7VSxwXX3CqWGNUxBVBuii2JT5VFRFChaExQ5OVyIVGIw6m1No4jIxg9jqPiQkKR/DFG6do5R00R31oRB7jMOUtqlF+V4t77OI6lFLbTI+KDY/8dX1LuQqFSuoTCeJZjpA4x5ZCkCYtQqLMVnxGADjFlJA7HGE/KNViZpxWR4rPWOo5jaw3mJXPJbp6wzAoh/PnzB+dJLDAxa645HJ6fuTB9YhsGee+HYaDcK4tZVOIgD7iMMaaUVIGheZom3COmUEg6E24OXHPrixQKc/u3kUrbibI5jqN8MsZQ0ubZt6j+vXc2lraYbq3FT4ZN06QOwMwKFgIgzekVlBMizxhzVpcHhbrEWmukhQ4DNQGLowYHcH0BVCnMaouzZBgG9/93JeB2zn2llESP9sNIEQo9mGCCPFVPS02h3ANiXvpJ0jln7cebG+Wi7n9rDjLYm1UEn+YHZITe3DreuVGZKfeCwmqoXrQRRzM7JOhroBMKJZ7e+8kYc71eEY3qp/SnMxSexQRRntd3XJ//htAeVBD2phTTaA3DUEpRoiBiEKPCv/PZPfI2b/G+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=52x52 at 0x7F2CBE332908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_it = iter(ds)\n",
    "print(type(ds))\n",
    "\n",
    "filenames = {ds.get_filename(i): i for i in range(len(ds))}\n",
    "file_idx = filenames['0808_0']\n",
    "# img1 = ds.get_max_bpp_img()\n",
    "img1 = ds[file_idx]\n",
    "print(img1.keys())\n",
    "if 13 in img1:\n",
    "    img1 = img1[13]\n",
    "print(img1['bpp'])\n",
    "show_tensor(img1['compressed'])\n",
    "for c in range(3):\n",
    "    print('res')\n",
    "    show_tensor(img1['raw'][c, ...].float() - img1['compressed'][c, ...].float(), normalize=True, show_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from fjcommon.no_op import NoOp\n",
    "\n",
    "import vis.safe_summary_writer\n",
    "import vis.summarizable_module\n",
    "from vis import image_summaries\n",
    "\n",
    "\n",
    "class _FakeSummaryWriter(vis.safe_summary_writer.SafeSummaryWriter):\n",
    "    def __init__(self):\n",
    "        self.cache = None\n",
    "        self.file_writer = NoOp\n",
    "        self.clear()\n",
    "\n",
    "    def add_scalar(self, tag, scalar_value, global_step=None):\n",
    "        self.cache[global_step][tag] = scalar_value\n",
    "\n",
    "    def add_image(self, tag, img_tensor, global_step=None, **kwargs):\n",
    "        if len(img_tensor.shape) == 2:\n",
    "            img = img_tensor.reshape(1, *img_tensor.shape)\n",
    "        img = image_summaries.to_image(img_tensor)  # make sure this does not raise\n",
    "        self.cache[global_step][tag] = img\n",
    "\n",
    "    def add_text(self, tag, text_string, global_step=None):\n",
    "        assert isinstance(text_string, str)\n",
    "        self.cache[global_step][tag] = text_string\n",
    "\n",
    "    def clear(self):\n",
    "        self.cache = defaultdict(dict)\n",
    "\n",
    "sw = _FakeSummaryWriter()\n",
    "s = vis.summarizable_module.Summarizer(sw)\n",
    "s.enable('val', 0)\n",
    "t.blueprint.register_summarizer(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t.blueprint.net.tail.sigmas.weight.shape\n",
    "# show_tensor(t.blueprint.net.tail.sigmas.weight.squeeze(), normalize=True, blow_up=10, mi=0)\n",
    "# show_tensor(t.blueprint.net.tail.means.weight.squeeze(), normalize=True, blow_up=10, mi=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers.notebook_dict import notebook_dict as nd\n",
    "\n",
    "# t.blueprint.net.prob_clfs[0].atrous.lin.weight[:] = 1/192.\n",
    "\n",
    "# print([n for n, _ in t.blueprint.net.named_parameters\n",
    "from helpers.global_config import global_config\n",
    "from blueprints.enhancement_blueprint import get_cin_classes\n",
    "from modules import conditional_instance_norm\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from helpers.quantized_tensor import NormalizedTensor\n",
    "\n",
    "for img in (img1, ):\n",
    "    x_n, bpps, _ = t.blueprint.unpack_batch_pad(img)# t.blueprint.get_padding_fac())\n",
    "    out = t.blueprint.forward(x_n, bpps)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1858352422714233"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from modules import prob_clf\n",
    "taus = nn.Parameter(torch.ones(1, 3, 5, 1, 1, requires_grad=True))\n",
    "\n",
    "# sigmas_orig = out.network_out.sigmas.clone()\n",
    "network_out = out.network_out \n",
    "\n",
    "# out.network_out = out_new\n",
    "\n",
    "optim = torch.optim.Adam([taus])\n",
    "t.blueprint.losses.train(True)\n",
    "\n",
    "# print(out.x_r.t.grad)\n",
    "for i in range(1000):\n",
    "    if taus.grad is not None:\n",
    "        taus.grad.detach_()\n",
    "        taus.grad.zero_()\n",
    "        taus.grad = None\n",
    "#     print(i, taus.reshape(-1).detach().cpu().numpy())\n",
    "    \n",
    "    new_sigmas = out.network_out.sigmas.detach() * taus\n",
    "    out_new = prob_clf.NetworkOutput(network_out.means.detach(), new_sigmas, network_out.pis.detach(), network_out.lambdas.detach())\n",
    "# \n",
    "    loss = t.blueprint.losses.loss_dmol_rgb(out.res, out_new).mean()\n",
    "#     loss = \n",
    "#     nll = self.loss_dmol_rgb(out.res, out.network_out, scale=0)\n",
    "\n",
    "    print('\\r' + str(loss.item()), end='')#, taus.grad)\n",
    "    loss.backward() \n",
    "#     print('backward done')\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(out)\n",
    "from modules import prob_clf\n",
    "\n",
    "sigmas_orig = out.network_out.sigmas.clone()\n",
    "network_out = out.network_out \n",
    "\n",
    "def _new_out(sigmas):\n",
    "    return prob_clf.NetworkOutput(network_out.means,\n",
    "                                    sigmas,\n",
    "                                    network_out.pis,\n",
    "                                    network_out.lambdas)\n",
    "\n",
    "for tau in (0.7, 0.8, 0.9, 1.0, 1.1):\n",
    "    out_ = _new_out(sigmas_orig * tau)\n",
    "    out.network_out = out_\n",
    "    loss = t.blueprint.losses(out).total_loss\n",
    "    print(loss)\n",
    "    \n",
    "print(sigmas_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lossy.other_codecs import bpg_compress_to, decode_bpg_to_png\n",
    "\n",
    "\n",
    "# raw_p = ds.get_raw_p(img_idx)\n",
    "# print(raw_p)\n",
    "\n",
    "# t = torch.from_numpy(np.array())\n",
    "import import_train_images\n",
    "from helpers.quantized_tensor import SymbolTensor\n",
    "\n",
    "\n",
    "def get_res(p1, p2):\n",
    "    _i1 = torch.from_numpy(np.array(Image.open(p1))).long()\n",
    "    _i2 = torch.from_numpy(np.array(Image.open(p2))).long()\n",
    "    _res = _i1 - _i2\n",
    "    return SymbolTensor(_res, L=511, centered=True).to_norm().t\n",
    "\n",
    "\n",
    "# im_o = import_train_images.resize(Image.open(raw_p), res=768*0.75)\n",
    "# im_o_p_jpg = 'some_tmp_debug_img.jpg'\n",
    "# im_o_p_png = 'some_tmp_debug_img.png'\n",
    "# im_o.save(im_o_p_jpg, quality=95)\n",
    "# im_o.save(im_o_p_png)\n",
    "\n",
    "# res_jpg_png = get_res(im_o_p_png, im_o_p_jpg)\n",
    "# for c in range(3):\n",
    "#     print(f'res_jpg_png{c}')\n",
    "#     show_tensor(res_jpg_png[:200, :200, c], normalize=True, blow_up=2)\n",
    "    \n",
    "\n",
    "# im_o_p = im_o_p_jpg\n",
    "# im_o_bpg_p = 'some_tmp_debug_img_bpg.png'\n",
    "\n",
    "# bpg_compress_to(im_o_p, im_o_p + '_bpg', 10)\n",
    "# decode_bpg_to_png(im_o_p + '_bpg', im_o_bpg_p)\n",
    "\n",
    "# im_o_t = torch.from_n/umpy(np.array(Image.open(im_o_p))).long()\n",
    "# im_o_bpg_t = torch.from_numpy(np.array(Image.open(im_o_bpg_p))).long()\n",
    "# img_2 = im_o_t - im_o_bpg_t\n",
    "# img_2 = SymbolTensor(img_2, L=511, centered=True).to_norm().t\n",
    "# show_tensor()\n",
    "\n",
    "\n",
    "# show_tensor(out.x_r.to_norm().t, normalize=True)\n",
    "# print(out.res.t.shape)\n",
    "\n",
    "sl = slice(None)\n",
    "bu = 2\n",
    "\n",
    "x_l = (out.x_r.t - out.res_sym.t).to(torch.uint8)\n",
    "print(x_l.min(), x_l.max())\n",
    "\n",
    "corrected_means = out.get_mean_img(t.blueprint.losses.loss_dmol_rgb)\n",
    "\n",
    "loss = t.blueprint.losses.loss_dmol_rgb(out.res, out.network_out)\n",
    "# show_tensor(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_mi, res_ma = out.res.t.min(), out.res.t.max()\n",
    "\n",
    "for c in range(3):\n",
    "    img_c = out.res.t[0, c, ...]\n",
    "#     img_c_2 = img_2[..., c]\n",
    "#     mi, ma = min(img_c.min(), img_c_2.min()), max(img_c.max(), img_c_2.max())\n",
    "#     print(img_c.min(), img_c.max())\n",
    "    print(f'x_r[{c}]')\n",
    "    show_tensor(out.x_r.t[0, c, sl, sl].to(torch.uint8), blow_up=bu, show_range=True)\n",
    "    print(f'x_l[{c}]')\n",
    "    show_tensor(x_l[0, c, sl, sl], blow_up=bu)\n",
    "#     print(f'JPG - BPG(JPG)[{c}]')\n",
    "#     show_tensor(img_c_2[:200, :200], normalize=True, blow_up=2, mi=mi, ma=ma)\n",
    "    print(f'out.res[{c}] (GT) == PNG - BPG(PNG)')\n",
    "    show_tensor(img_c[sl, sl], normalize=True, blow_up=bu, show_range=True, mi=res_mi, ma=res_ma)#, mi=mi, ma=ma)\n",
    "    \n",
    "#     show_tensor(out.x_r.t[0,c,...].float() - x_l[0, c, ...].float(), normalize=True, blow_up=bu)\n",
    "    \n",
    "# for c in range(3):\n",
    "    print(f'predicted_mean[{c}]')\n",
    "    show_tensor(corrected_means[0, c, sl, sl], normalize=True, blow_up=bu, show_range=True, mi=res_mi, ma=res_ma)\n",
    "    diff = out.res.t - corrected_means\n",
    "    print(f'res - predicted_mean[{c}]')\n",
    "    show_tensor(diff[0, c, sl, sl], normalize=True, blow_up=bu, show_range=True)\n",
    "_, C, K, _, _ = out.network_out.sigmas.shape\n",
    "    \n",
    "    \n",
    "logit_pis_sm = F.softmax(out.network_out.pis, dim=2)  # NCKHW, pi_k\n",
    "\n",
    "scaled_sigmas = (out.network_out.sigmas * logit_pis_sm).sum(2)\n",
    "# scaled_means  = (out.network_out.means  * logit_pis_sm).sum(2)\n",
    "\n",
    "\n",
    "for c in range(C):\n",
    "    print('---')\n",
    "    print(f'SIGMA_scaled c{c};')\n",
    "    show_tensor(scaled_sigmas[0, c, sl, sl], normalize=True, blow_up=bu, show_range=True)\n",
    "    print(f'MEAN_corrected_scaled c{c}')\n",
    "    show_tensor(corrected_means[0, c, sl, sl], normalize=True, blow_up=bu, show_range=True, mi=res_mi, ma=res_ma)\n",
    "\n",
    "print('***\\n***\\n***\\n***\\n***')\n",
    "\n",
    "# normalized_pis = \n",
    "\n",
    "for c in range(C):\n",
    "    for k in range(K):\n",
    "        print(f'PI c{c};k{k}')\n",
    "        show_tensor(logit_pis_sm[0, c, k, sl, sl], normalize=True, blow_up=bu, show_range=True, mi=0, ma=1)\n",
    "        print(f'SIGMA c{c};k{k}')\n",
    "        show_tensor(out.network_out.sigmas[0, c, k, sl, sl], normalize=True, blow_up=bu, show_range=True)\n",
    "        print(f'MEAN c{c};k{k}')\n",
    "        show_tensor(out.network_out.means[0, c, k, sl, sl], normalize=True, blow_up=bu, show_range=True, mi=res_mi, ma=res_ma)\n",
    "                         \n",
    "\n",
    "\n",
    "\n",
    "# show_tensor(t.blueprint.net.heads[0].head[1].gamma, normalize=True)\n",
    "\n",
    "# show_tensor(t.blueprint.net.prob_clfs[0].tail.means[0].gamma, normalize=True)\n",
    "# print(t.blueprint.net.prob_clfs[0].tail.means[0].beta)\n",
    "# loss_pc, nonrecursive_bpsps, _ = t.blueprint.get_loss(out)\n",
    "\n",
    "# print(nonrecursive_bpsps)\n",
    "\n",
    "# #     t.blueprint.add_image_summaries(sw, out, 0, 'val')\n",
    "\n",
    "# print('loss', loss_pc)\n",
    "# #     print(sw.cache[0].keys()) \n",
    "# lossy_rec = sw.cache[0]['val/predicted_mean']\n",
    "# print(lossy_rec.shape)\n",
    "# IPython.display.display(Image.fromarray((lossy_rec)))\n",
    "\n",
    "# gt = s.get()[0, ...].permute(1, 2, 0).float()\n",
    "# diff = torch.from_numpy(lossy_rec).float() - gt\n",
    "# diff_arr = show_tensor(diff, normalize=True)\n",
    "\n",
    "# Image.fromarray(diff_arr).save('test_db.png')\n",
    "# print(os.path.getsize('test_db.png') * 8 / np.prod(diff_arr.shape))\n",
    "\n",
    "# img_raw = sw.cache[0]['val/dmll/0/c2'][...]\n",
    "# img = Image.fromarray(img_raw)\n",
    "# IPython.display.display(img)\n",
    "\n",
    "# #     w = t.blueprint.net.prob_clfs[0].atrous.lin.weight  # 12, 192\n",
    "# #     w = w[2*3*1:3*3*1, ...]\n",
    "# #     plt.figure()\n",
    "# #     for k in range(w.shape[0]):\n",
    "# #         plt.plot(range(w.shape[1]), w[k, :, 0, 0].detach().numpy())\n",
    "\n",
    "\n",
    "# #     print('bitcost pp', nd['bitcost'][0, 2, 20:25, 20:25])\n",
    "\n",
    "# #     bc = sw.cache[0]['val/dmll/bitcost/0'][...]\n",
    "\n",
    "# #     IPython.display.display(Image.fromarray((bc > 0).astype(np.uint8) * 255))\n",
    "\n",
    "# #     IPython.display.display(Image.fromarray(sw.cache[0]['val/dmll/bitcost/0'][...]))\n",
    "\n",
    "# #     IPython.display.display(Image.fromarray(sw.cache[0]['val/bn/1'][...]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(os.listdir('tmp/new_age_feat_maps/'))\n",
    "# # IPython.display.display(Image.open('tmp/new_age_feat_maps/after_body_0000000000.png'))\n",
    "# IPython.display.display(Image.open('tmp/new_age_feat_maps/head_0000000000.png'))\n",
    "# IPython.display.display(Image.open('tmp/new_age_feat_maps/body_bs_0000000000.png'))\n",
    "# IPython.display.display(Image.open('tmp/new_age_feat_maps/body_as_0000000000.png'))\n",
    "# IPython.display.display(Image.open('tmp/new_age_feat_maps/final_sigmas_0000000000.png'))\n",
    "# IPython.display.display(Image.open('tmp/new_age_feat_maps/sigmas_0000000000.png'))\n",
    "# IPython.display.display(Image.open('tmp/new_age_feat_maps/means_0000000000.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitcoding import coders_helpers\n",
    "\n",
    "\n",
    "\n",
    "def get_C(l, x, chan=0):\n",
    "    c = coders_helpers.CodingCDFNonshared(l, 3, t.blueprint.losses.loss_dmol_rgb)\n",
    "    c.c_cur = chan\n",
    "    C = c.get_next_C(x)\n",
    "    return _get_C_cur_weighted(C.logit_probs_c_sm, c.targets, C.means_c, C.log_scales_c)\n",
    "\n",
    "def _get_C_cur_weighted(logit_probs_softmax_c, targets, means_c, log_scales_c):\n",
    "    C_cur = _get_C_cur(targets, means_c, log_scales_c)  # NKHWL\n",
    "    C_cur = C_cur.mul(logit_probs_softmax_c.unsqueeze(-1)).sum(1)  # NHWL\n",
    "    return C_cur\n",
    "\n",
    "\n",
    "def _get_C_cur(targets, means_c, log_scales_c):  # NKHWL\n",
    "    \"\"\"\n",
    "    :param targets: Lp floats\n",
    "    :param means_c: NKHW\n",
    "    :param log_scales_c: NKHW\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # NKHW1\n",
    "#     print(log_scales_c.unique)\n",
    "    inv_stdv = torch.exp(-log_scales_c).unsqueeze(-1)\n",
    "#     print(inv_stdv.unique)\n",
    "    # NKHWL'\n",
    "    centered_targets = (targets - means_c.unsqueeze(-1))\n",
    "#     print(centered_targets.shape, inv_stdv.shape)\n",
    "    # NKHWL'\n",
    "    arg = centered_targets.mul(inv_stdv)\n",
    "#     print(arg.unique())\n",
    "    cdf = arg.sigmoid()  # sigma' * (x - mu)\n",
    "    return cdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(out)\n",
    "P = out.network_out\n",
    "dmll = t.blueprint.losses.loss_dmol_rgb\n",
    "\n",
    "img_raw = img1['raw'].float()\n",
    "\n",
    "means = P.means\n",
    "mean_ma,_ = torch.max(means,dim=2)\n",
    "mean_mi,_ = torch.min(means,dim=2)\n",
    "print(mean_ma.shape)\n",
    "mean_diffs = mean_ma - mean_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tensor(mean_diffs,normalize=True)\n",
    "x_range = (153,163)\n",
    "y_range = (183,184)\n",
    "show_tensor(img_raw[..., slice(*x_range), slice(*y_range)],normalize=True, blow_up=10)\n",
    "print(means.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# x_r, x_l = x_n\n",
    "dmll.plot(out.res, P, plt, x_range=x_range, y_range=y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "P = out.P[0]\n",
    "\n",
    "x = t.blueprint.losses.loss_dmol_rgb.to_bn(p)\n",
    "\n",
    "\n",
    "\n",
    "c1 = get_C(P, x, 0).detach().numpy()\n",
    "c2 = get_C(P, x, 1).detach().numpy()\n",
    "c3 = get_C(P, x, 2).detach().numpy()\n",
    "print(c1.shape)\n",
    "\n",
    "fig = None\n",
    "\n",
    "f, axs = plt.subplots(3, 1, sharex=True)\n",
    "\n",
    "for ci, ax in zip((c1, c2, c3), axs):\n",
    "    for x in range(40, 50, 1):\n",
    "        for y in range(40, 50, 1):\n",
    "            data = ci[0, int(x), int(y), ...]\n",
    "#                 print(data)\n",
    "            ax.plot(np.arange(257), data)\n",
    "plt.show()\n",
    "\n",
    "# # def f(x=list(range(c1.shape[1])), y=list(range(c1.shape[2]))):\n",
    "# def f(x, y):\n",
    "#     plt.clf()\n",
    "#     data = c1[0, int(x), int(y), ...]\n",
    "# #    print(x, y, data)\n",
    "#     plt.plot(np.arange(257), data)\n",
    "# #     plt.ylim(0, 1)\n",
    "#     plt.show()\n",
    "\n",
    "# interactive_plot = interactive(f, x=(0, c1.shape[1]), y=(0, c1.shape[2]))\n",
    "# output = interactive_plot.children[-1]\n",
    "# output.layout.height = '550px'\n",
    "# interactive_plot\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = out.P[0][0, ...]\n",
    "K = P.shape[0]//3//4\n",
    "print(K)\n",
    "H, W = P.shape[1], P.shape[2]\n",
    "\n",
    "l = P.reshape(4, 3, K, H, W)\n",
    "\n",
    "logit_probs = F.softmax(l[0, ...], dim=1)  # CKHW\n",
    "means = l[1, ...]  # NCKHW\n",
    "log_scales = torch.clamp(l[2, ...], min=-7)  # NCKHW, is >= -7\n",
    "coeffs = l[3, ...]\n",
    "\n",
    "for c in range(3):\n",
    "    for k in range(K):\n",
    "        logit_probs_c_k =  logit_probs[0, k, ...]\n",
    "        if logit_probs_c_k.mean() < 0.01:\n",
    "            continue\n",
    "        print(k, means.min(), means.max(), logit_probs_c_k.mean())\n",
    "        show_tensor(logit_probs_c_k.mul(255).round().to(torch.uint8), normalize=False)\n",
    "        means_c_k = means[c, k, ...]\n",
    "    #     means_c_k[logit_probs_c_k < 1e-3] = 0\n",
    "        print('Means', c, means_c_k[10:20, 10:20])\n",
    "        show_tensor(means_c_k, normalize=True)\n",
    "\n",
    "        scales_c_k = log_scales[c, k, ...]\n",
    "        print('Scales', c, scales_c_k[10:20, 10:20])\n",
    "\n",
    "        coeffs_c_k = coeffs[c, k, ...]\n",
    "        print('Coeffs', c, coeffs_c_k[10:20, 10:20])\n",
    "\n",
    "        scales_c_k[logit_probs_c_k < 1e-3] = 0\n",
    "        show_tensor(scales_c_k, normalize=True, mi=0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sigma = P[10:20, ...]\n",
    "for k in range(10):\n",
    "    show_tensor(sigma[k, ...], normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyt11)",
   "language": "python",
   "name": "pyt11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
